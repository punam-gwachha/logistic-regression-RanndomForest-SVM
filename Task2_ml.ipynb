{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz6fjUUZmqtxKxCN6z3z/R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/punam-gwachha/logistic-regression-RanndomForest-SVM/blob/main/Task2_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import required Libraries"
      ],
      "metadata": {
        "id": "qx85TO0jdjB-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yM84A0Z2dUJc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, f1_score, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load training and testing datasets"
      ],
      "metadata": {
        "id": "VJZwE8NadyO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your  Training dataset\n",
        "train_data = pd.read_csv('/content/train_set.csv')\n",
        "train_data.head()\n",
        "\n",
        "# Load your  Testing dataset\n",
        "test_data = pd.read_csv('/content/test_set.csv')\n",
        "\n",
        "# Load your blind test set dataset\n",
        "blind_test_data = pd.read_csv('/content/blinded_test_set.csv')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "P24IXp9bdrd8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# preprocessing and Feature Engineering\n"
      ],
      "metadata": {
        "id": "Kw8dkhUrmClM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Separate features and target i.e CLASS for training set\n",
        "#and also non informative colum i.e. ID\n",
        "X_train = train_data.drop(columns=['CLASS','ID'])\n",
        "y_train = train_data['CLASS']\n",
        "\n",
        "# Separate features and target for testing set\n",
        "X_test = test_data.drop(columns=['CLASS','ID'])\n",
        "y_test = test_data['CLASS']\n",
        "\n",
        "# X_train.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TzKpSmxDmHew"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. check wherther there is any missing value or not.\n",
        "# 0 i.e there is no any missing value\n",
        "X_train.isnull().sum()\n",
        "\n",
        "# # check for infinite values of train dataset\n",
        "np.isinf(X_train).sum()\n",
        "\n",
        "# check for infinite and missing values for test datset\n",
        "X_test.isnull().sum()\n",
        "np.isinf(X_test).sum()"
      ],
      "metadata": {
        "id": "GQ8NY_I5oamt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "collapsed": true,
        "outputId": "78002093-46d6-4b27-fb47-b8847d1ba9c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Feature_1       0\n",
              "Feature_2       0\n",
              "Feature_3       0\n",
              "Feature_4       0\n",
              "Feature_5       0\n",
              "               ..\n",
              "Feature_3234    0\n",
              "Feature_3235    0\n",
              "Feature_3236    0\n",
              "Feature_3237    0\n",
              "Feature_3238    0\n",
              "Length: 3238, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Feature_1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_5</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_3234</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_3235</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_3236</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_3237</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature_3238</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3238 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fill the infinite value and NAN values"
      ],
      "metadata": {
        "id": "HWYJS7AtjDH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Even though the above code checks for missing values it's possible that this check didn't identify all forms of missing data\n",
        "# or that missing values were introduced or not handled correctly during subsequent steps.\n",
        "# Clean train data: replace infs(infinite value)  and fill NaNs(Not a number)\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_train.fillna(X_train.mean(), inplace=True)\n",
        "\n",
        "# Clean and prepare test set\n",
        "X_test.replace([np.inf, -np.inf], np.nan)\n",
        "X_test.fillna(X_test.mean(), inplace=True)\n"
      ],
      "metadata": {
        "id": "e8_fsNlojCwo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train )\n",
        "\n",
        "# Transform test data using the same scaler\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 4. Convert scaled data back to DataFrame\n",
        "X_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EySxdWCXrR3W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection"
      ],
      "metadata": {
        "id": "wD1XPNPi3eeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Select top K features using ANOVA F-score\n",
        "k = 2500\n",
        "selector = SelectKBest(score_func=f_classif, k=k)\n",
        "# Use X_train and y_train for feature selection\n",
        "X_selected = selector.fit_transform(X_train_scaled, y_train) # Apply feature selection on scaled training data\n",
        "\n",
        "# Step 2: Get the selected feature names\n",
        "selected_mask = selector.get_support()  # Boolean mask\n",
        "# Get feature names from the original scaled training features\n",
        "# Note: We need to get column names from the scaled DataFrame\n",
        "selected_features = X_scaled_df.columns[selected_mask]\n",
        "\n",
        "# Step 3: Create new DataFrame with selected features for TRAIN\n",
        "X_selected_df_train = pd.DataFrame(X_selected, columns=selected_features)\n",
        "\n",
        "# Step 4: Apply the same feature selection to the SCALED TEST data\n",
        "X_test_selected = selector.transform(X_test_scaled) # Use the *same* selector fitted on training data\n",
        "X_selected_df_test = pd.DataFrame(X_test_selected, columns=selected_features)\n",
        "\n",
        "X_selected_df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "_dZ_9gaI0nu8",
        "outputId": "3285c1b4-1b65-4458-ad8e-0fc43ef7ccb0",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [1719 1731 1733 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919\n",
            " 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933\n",
            " 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122\n",
            " 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2248 2249 2255\n",
            " 2259 2376 2377 2383 2387 2504 2505 2511 2515 2632 2633 2639 2640 2643\n",
            " 2758 2759 2760 2761 2762 2763 2764 2765 2767 2769 2771 2772 2773 2886\n",
            " 2887 2888 2889 2890 2891 2892 2893 2895 2897 2899 2900 2901 2937 2938\n",
            " 2939 2940 2941 2977 2978 2979 2980 2981 3096 3097 3103 3106 3224 3225\n",
            " 3231 3234] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
              "0  -0.756859  -0.756281  -0.768458   1.790937  -0.703377  -0.622357   \n",
              "1  -0.684660  -0.686690  -0.980408   0.279318   0.567037   0.393269   \n",
              "2  -0.381832  -0.380581  -0.235997   0.738313  -0.658969  -0.592319   \n",
              "3   0.231255   0.232764   0.851293   0.408853  -1.186714  -0.927422   \n",
              "4   0.203521   0.203601   0.171085  -0.825213   0.093786  -0.031715   \n",
              "\n",
              "   Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_3224  \\\n",
              "0   0.757830  -0.722168   0.757830    0.038485  ...     -1.903318   \n",
              "1  -0.768013   0.617284  -0.768013   -0.059407  ...     -0.133632   \n",
              "2   0.689108  -0.672790   0.689108   -0.062952  ...     -0.972867   \n",
              "3   1.599928  -1.272312   1.599928   -0.063502  ...     -0.486524   \n",
              "4  -0.308667   0.138226  -0.308667   -0.058745  ...      0.680798   \n",
              "\n",
              "   Feature_3227  Feature_3228  Feature_3229  Feature_3230  Feature_3231  \\\n",
              "0      1.608494      1.608494     -1.903318     -1.903318     -0.795461   \n",
              "1     -0.045529     -0.045529     -0.133632     -0.133632     -0.683039   \n",
              "2      0.509137      0.509137     -0.972867     -0.972867     -0.396858   \n",
              "3      0.354945      0.354945     -0.486524     -0.486524      0.283390   \n",
              "4     -0.574604     -0.574604      0.680798      0.680798      0.173152   \n",
              "\n",
              "   Feature_3233  Feature_3234  Feature_3237  Feature_3238  \n",
              "0     -0.386250     -1.156615      1.487482     -1.156615  \n",
              "1     -0.309647     -0.493571      0.542650     -0.493571  \n",
              "2     -0.308825     -0.995803      1.137855     -0.995803  \n",
              "3     -0.154057     -0.763600      0.852824     -0.763600  \n",
              "4      0.084921      0.703383     -0.859371      0.703383  \n",
              "\n",
              "[5 rows x 2500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0b9a343-7125-4149-ade7-da5ca9229fa0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature_1</th>\n",
              "      <th>Feature_2</th>\n",
              "      <th>Feature_3</th>\n",
              "      <th>Feature_4</th>\n",
              "      <th>Feature_5</th>\n",
              "      <th>Feature_6</th>\n",
              "      <th>Feature_7</th>\n",
              "      <th>Feature_8</th>\n",
              "      <th>Feature_9</th>\n",
              "      <th>Feature_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Feature_3224</th>\n",
              "      <th>Feature_3227</th>\n",
              "      <th>Feature_3228</th>\n",
              "      <th>Feature_3229</th>\n",
              "      <th>Feature_3230</th>\n",
              "      <th>Feature_3231</th>\n",
              "      <th>Feature_3233</th>\n",
              "      <th>Feature_3234</th>\n",
              "      <th>Feature_3237</th>\n",
              "      <th>Feature_3238</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.756859</td>\n",
              "      <td>-0.756281</td>\n",
              "      <td>-0.768458</td>\n",
              "      <td>1.790937</td>\n",
              "      <td>-0.703377</td>\n",
              "      <td>-0.622357</td>\n",
              "      <td>0.757830</td>\n",
              "      <td>-0.722168</td>\n",
              "      <td>0.757830</td>\n",
              "      <td>0.038485</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.903318</td>\n",
              "      <td>1.608494</td>\n",
              "      <td>1.608494</td>\n",
              "      <td>-1.903318</td>\n",
              "      <td>-1.903318</td>\n",
              "      <td>-0.795461</td>\n",
              "      <td>-0.386250</td>\n",
              "      <td>-1.156615</td>\n",
              "      <td>1.487482</td>\n",
              "      <td>-1.156615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.684660</td>\n",
              "      <td>-0.686690</td>\n",
              "      <td>-0.980408</td>\n",
              "      <td>0.279318</td>\n",
              "      <td>0.567037</td>\n",
              "      <td>0.393269</td>\n",
              "      <td>-0.768013</td>\n",
              "      <td>0.617284</td>\n",
              "      <td>-0.768013</td>\n",
              "      <td>-0.059407</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.133632</td>\n",
              "      <td>-0.045529</td>\n",
              "      <td>-0.045529</td>\n",
              "      <td>-0.133632</td>\n",
              "      <td>-0.133632</td>\n",
              "      <td>-0.683039</td>\n",
              "      <td>-0.309647</td>\n",
              "      <td>-0.493571</td>\n",
              "      <td>0.542650</td>\n",
              "      <td>-0.493571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.381832</td>\n",
              "      <td>-0.380581</td>\n",
              "      <td>-0.235997</td>\n",
              "      <td>0.738313</td>\n",
              "      <td>-0.658969</td>\n",
              "      <td>-0.592319</td>\n",
              "      <td>0.689108</td>\n",
              "      <td>-0.672790</td>\n",
              "      <td>0.689108</td>\n",
              "      <td>-0.062952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.972867</td>\n",
              "      <td>0.509137</td>\n",
              "      <td>0.509137</td>\n",
              "      <td>-0.972867</td>\n",
              "      <td>-0.972867</td>\n",
              "      <td>-0.396858</td>\n",
              "      <td>-0.308825</td>\n",
              "      <td>-0.995803</td>\n",
              "      <td>1.137855</td>\n",
              "      <td>-0.995803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.231255</td>\n",
              "      <td>0.232764</td>\n",
              "      <td>0.851293</td>\n",
              "      <td>0.408853</td>\n",
              "      <td>-1.186714</td>\n",
              "      <td>-0.927422</td>\n",
              "      <td>1.599928</td>\n",
              "      <td>-1.272312</td>\n",
              "      <td>1.599928</td>\n",
              "      <td>-0.063502</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.486524</td>\n",
              "      <td>0.354945</td>\n",
              "      <td>0.354945</td>\n",
              "      <td>-0.486524</td>\n",
              "      <td>-0.486524</td>\n",
              "      <td>0.283390</td>\n",
              "      <td>-0.154057</td>\n",
              "      <td>-0.763600</td>\n",
              "      <td>0.852824</td>\n",
              "      <td>-0.763600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.203521</td>\n",
              "      <td>0.203601</td>\n",
              "      <td>0.171085</td>\n",
              "      <td>-0.825213</td>\n",
              "      <td>0.093786</td>\n",
              "      <td>-0.031715</td>\n",
              "      <td>-0.308667</td>\n",
              "      <td>0.138226</td>\n",
              "      <td>-0.308667</td>\n",
              "      <td>-0.058745</td>\n",
              "      <td>...</td>\n",
              "      <td>0.680798</td>\n",
              "      <td>-0.574604</td>\n",
              "      <td>-0.574604</td>\n",
              "      <td>0.680798</td>\n",
              "      <td>0.680798</td>\n",
              "      <td>0.173152</td>\n",
              "      <td>0.084921</td>\n",
              "      <td>0.703383</td>\n",
              "      <td>-0.859371</td>\n",
              "      <td>0.703383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 2500 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0b9a343-7125-4149-ade7-da5ca9229fa0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0b9a343-7125-4149-ade7-da5ca9229fa0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0b9a343-7125-4149-ade7-da5ca9229fa0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d92f6af4-a7b5-4b99-8ce8-abbbef4aed4d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d92f6af4-a7b5-4b99-8ce8-abbbef4aed4d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d92f6af4-a7b5-4b99-8ce8-abbbef4aed4d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_selected_df_train"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 1.Logistic Regression with Hyperparameter Tuning\n"
      ],
      "metadata": {
        "id": "rWO8G-lhla1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameter = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l2'],\n",
        "  }\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "# Fit the GridSearchCV on the feature-selected and scaled training data\n",
        "grid_search = GridSearchCV(log_reg, parameter, cv=5, scoring='roc_auc')\n",
        "grid_search.fit(X_selected_df_train, y_train) # Fit on feature-selected TRAIN data\n",
        "\n",
        "# best_model gives LogisticRegression model with the best hyperparameters found from the grid search\n",
        "best_model = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "DLSH-KvrlOIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f120322c-9986-46de-d71a-be671b80fdf5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Predict and Evaluate for logistic regression\n"
      ],
      "metadata": {
        "id": "7IrGiqzrmKyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the feature-selected and scaled test data for prediction\n",
        "y_test_pred = best_model.predict(X_selected_df_test)\n",
        "y_test_proba = best_model.predict_proba(X_selected_df_test)[:, 1]\n",
        "\n",
        "# Confusion Matrix for Specificity Calculation\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
        "\n",
        "# Metrics calculation and Display metrics\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"AUROC:{roc_auc_score(y_test, y_test_proba):.4f}\")\n",
        "print(f\"Sensitivity (Recall):{recall_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"specificity:{ tn / (tn + fp):.4f}\")\n",
        "print(f\"f1: {f1_score(y_test, y_test_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgfcZjtvmLUW",
        "outputId": "7e80af00-151b-4f03-bc54-09984c2cd0a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6300\n",
            "AUROC:0.6576\n",
            "Sensitivity (Recall):0.4762\n",
            "specificity:0.7414\n",
            "f1: 0.5195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Blinded test for logistic regression"
      ],
      "metadata": {
        "id": "H1I4akeJ8OAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the blind test data first\n",
        "X_blind = blind_test_data.drop(columns=[\"ID\"]).replace([np.inf, -np.inf], np.nan)\n",
        "X_blind.fillna(X_blind.mean(), inplace=True)\n",
        "\n",
        "# Apply the same scaler fitted on the training data to the blind test data\n",
        "X_blind_scaled = scaler.transform(X_blind)\n",
        "\n",
        "# Convert scaled blind data back to DataFrame to retain feature names\n",
        "X_blind_scaled_df = pd.DataFrame(X_blind_scaled, columns=X_blind.columns)\n",
        "\n",
        "# Use the selected_features list to ensure correct column order and names\n",
        "X_blind_selected_df = X_blind_scaled_df[selected_features]\n",
        "\n",
        "# Now predict using the feature-selected blind data\n",
        "blind_probs = best_model.predict_proba(X_blind_selected_df)\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({\n",
        "    # Use the original blind_test_data for ID as X_blind_selected_df might have a different index\n",
        "    \"ID\": blind_test_data[\"ID\"],\n",
        "    \"class_0\": blind_probs[:, 0],\n",
        "    \"class_1\": blind_probs[:, 1]\n",
        "})\n",
        "submission.to_csv(\"logreg_blinded_predictions.csv\", index=False)"
      ],
      "metadata": {
        "id": "L3hYM3ni8Osl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Random Forest"
      ],
      "metadata": {
        "id": "ODKBFZy12wYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Random Forest model implementation\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define parameter grid for GridSearch\n",
        "param_rf = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [None, 10, 20]\n",
        "}\n",
        "\n",
        "# Perform grid search with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(rf, param_rf, cv=5, scoring=\"roc_auc\")\n",
        "grid_search.fit(X_selected_df_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_rf= grid_search.best_estimator_\n",
        "\n",
        "# Predict on the scaled and feature-selected test data\n",
        "rf_pred = best_rf.predict(X_selected_df_test)\n",
        "rf_proba = best_rf.predict_proba(X_selected_df_test)[:, 1]\n",
        "\n",
        "# Metrics calculation and Display metrics\n",
        "print(f\"Random Forest Accuracy: {accuracy_score(y_test, rf_pred):.4f}\")\n",
        "print(f\"Random Forest AUROC:{roc_auc_score(y_test, rf_proba):.4f}\")\n",
        "print(f\"Random Forest Sensitivity (Recall):{recall_score(y_test, rf_pred):.4f}\")\n",
        "print(f\"Random Forest specificity:{ tn / (tn + fp):.4f}\")\n",
        "print(f\"Random Forest f1: {f1_score(y_test, rf_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3f-Cng-GAjk",
        "outputId": "07e9b686-3c42-45d7-c072-0153c19fff69"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.6300\n",
            "Random Forest AUROC:0.6539\n",
            "Random Forest Sensitivity (Recall):0.3333\n",
            "Random Forest specificity:0.7414\n",
            "Random Forest f1: 0.4308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Blinded test for random forest"
      ],
      "metadata": {
        "id": "6LfOVa0O8cZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now predict using the feature-selected blind data\n",
        "blind_probs = best_rf.predict_proba(X_blind_selected_df)\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({\n",
        "    # Use the original blind_test_data for ID as X_blind_selected_df might have a different index\n",
        "    \"ID\": blind_test_data[\"ID\"],\n",
        "    \"class_0\": blind_probs[:, 0],\n",
        "    \"class_1\": blind_probs[:, 1]\n",
        "})\n",
        "submission.to_csv(\"randomforest_blinded_predictions.csv\", index=False)"
      ],
      "metadata": {
        "id": "PxHIxR1u8frt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Support Vector machine"
      ],
      "metadata": {
        "id": "rEee58KYAem5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='rbf', probability=True, class_weight=\"balanced\", random_state=42)\n",
        "\n",
        "# Define parameter grid for GridSearch\n",
        "param_svm = {\n",
        "    \"C\": [0.1, 1, 10],\n",
        "    \"gamma\": ['scale', 0.01, 0.001]\n",
        "}\n",
        "\n",
        "# Perform grid search with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(svm, param_svm, cv=5, scoring=\"roc_auc\")\n",
        "grid_search.fit(X_selected_df_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_svm = grid_search.best_estimator_\n",
        "\n",
        "# Predict on the scaled and feature-selected test data\n",
        "svm_pred = best_svm.predict(X_selected_df_test)\n",
        "svm_proba = best_svm.predict_proba(X_selected_df_test)[:, 1]\n",
        "\n",
        "# Metrics calculation and Display metrics\n",
        "print(f\"svm Accuracy: {accuracy_score(y_test, svm_pred):.4f}\")\n",
        "print(f\"svm AUROC:{roc_auc_score(y_test, svm_proba ):.4f}\")\n",
        "print(f\"svm Sensitivity (Recall):{recall_score(y_test, svm_pred):.4f}\")\n",
        "print(f\"svm specificity:{ tn / (tn + fp):.4f}\")\n",
        "print(f\"svm f1: {f1_score(y_test,svm_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn_FxJbeAfBk",
        "outputId": "71f2b059-42a3-4ffb-c05b-608428bd902e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm Accuracy: 0.6100\n",
            "svm AUROC:0.3087\n",
            "svm Sensitivity (Recall):0.8810\n",
            "svm specificity:0.7414\n",
            "svm f1: 0.6549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Blind test for svm"
      ],
      "metadata": {
        "id": "il0n0qtJClU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on blinded test set\n",
        "svm_blind_probs = best_svm.predict_proba(X_blind_selected_df)\n",
        "svm_output = pd.DataFrame({\n",
        "    \"ID\": blind_test_data[\"ID\"],\n",
        "    \"class_0\": svm_blind_probs[:, 0],\n",
        "    \"class_1\": svm_blind_probs[:, 1]\n",
        "})\n",
        "svm_output.to_csv(\"svm_blinded_predictions.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "qlADcChiBYWk"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}